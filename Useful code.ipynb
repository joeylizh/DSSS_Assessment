{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e9651cd-3c33-4b26-9edd-90f3caecad0a",
   "metadata": {},
   "source": [
    "# This notebook is for the codes have not been used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c418d841-0e62-43fc-a862-3c914bff8ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(1)\n",
    "\n",
    "# remove_n = 892920 # The number of rows with random index\n",
    "\n",
    "# # Removes these rows from dataframe and returns a subset dataframe.\n",
    "# drop_indices = np.random.choice(df.index, remove_n, replace=False)\n",
    "# df_subset = df.drop(drop_indices)\n",
    "\n",
    "# df_subset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf8e6f-cb70-4d8e-b8d1-5a6a8ab914bd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a5287-947e-4a9c-8168-9d4f30e7165b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"ID\"] = df.groupby([\"Transaction_unique_identifier\"]).ngroup()\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89cf2f53-f9c1-4f70-8d7f-048f5b346fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # shift column 'Name' to first position\n",
    "# first_column = df.pop(\"ID\")\n",
    "\n",
    "# # insert column using insert(position,column_name,\n",
    "# # first_column) function\n",
    "# df.insert(0, \"ID\", first_column)\n",
    "\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7348641-7bb2-4f25-af33-554053a6c236",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25e663-4bca-4d9a-83d0-38b0a0778d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install geopandas\n",
    "# pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d7b2d-3b53-45b7-a7ec-2b08405034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geopy\n",
    "# from geopy.geocoders import Nominatim\n",
    "# from geopy.extra.rate_limiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db7290d-f393-420f-a783-2eaf9d95be36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# locator = Nominatim(user_agent='myGeocoder')\n",
    "# # 1 - conveneint function to delay between geocoding calls\n",
    "# geocode = RateLimiter(locator.geocode, min_delay_seconds=0.1)\n",
    "# # 2- - create location column\n",
    "# df['location'] = df['Postcode'].apply(geocode)\n",
    "# # 3 - create longitude, laatitude and altitude from location column (returns tuple)\n",
    "# df['point'] = df['location'].apply(lambda loc: tuple(loc.point) if loc else None)\n",
    "# # 4 - split point column into latitude, longitude and altitude columns\n",
    "# df[['latitude', 'longitude', 'altitude']] = pd.DataFrame(df['point'].tolist(), index=df.index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2620f9d-4d66-47a9-bc5a-9e19f1c17a57",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde8270-f0d6-4541-a869-ed743083c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import geocoder\n",
    "\n",
    "# def get_geocoder(postal_code_from_df):\n",
    "#      # initialize your variable to None\n",
    "#      lat_lng_coords = None\n",
    "#      # loop until you get the coordinates\n",
    "#      while(lat_lng_coords is None):\n",
    "#        g = geocoder.google('{}, Toronto, Ontario'.format(postal_code_from_df))\n",
    "#        lat_lng_coords = g.latlng\n",
    "#      latitude = lat_lng_coords[0]\n",
    "#      longitude = lat_lng_coords[1]\n",
    "#      return latitude,longitude\n",
    "\n",
    "\n",
    "# df['Latitude'], df['Longitude'] = zip(*df['Postcode'].apply(get_geocoder))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3ad99c-1638-4365-b7a7-7330ec7a3cba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690ce906-2227-4231-ac75-5fe3fc9bbfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = pd.read_csv('https://raw.githubusercontent.com/joeylizh/DSSS_Assessment/main/df_subset.csv')\n",
    "\n",
    "df_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c9f958-fdbf-46be-8841-6d5633832d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_subset.to_csv(r'Data/df_subset.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ff4a60-5a84-49a8-98dd-16066ad082e3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a796b3-c90b-4a86-833d-eb0a2eee8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric1 = pd.get_dummies(df_subset, columns = ['Building_Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009813d5-b964-4587-914e-4cce77cfba90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric2 = pd.get_dummies(df_numeric1, columns = ['Tenure'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a317ba-da09-4e93-a095-bf626d4e0dd6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d2a299-9867-4b54-9dc3-be16c057fd0b",
   "metadata": {},
   "source": [
    "Sometimes, it is helpful to plot the influence of a single hyperparameter on the training and development score to find out whether the model is overfitting or underfitting. This plot is called Validation curve.\n",
    "\n",
    "The function validation_score is helpful in this case. Similar to GridSearchCV, this function is based on cross-validation.\n",
    "\n",
    "n_estimators_range = [10,20,30,40,50,70,100,150,200]\n",
    "\n",
    "train_scores, valid_scores = validation_curve(estimator=RandomForestRegressor(), \n",
    "                                              X=X_train, y=y_train, \n",
    "                                              param_name=\"n_estimators\",\n",
    "                                              param_range=n_estimators_range,\n",
    "                                              cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fbe5d7-8db2-4922-a70f-c5a981db638d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_range = [10,20,30,40,50,70,100,150,200]\n",
    "\n",
    "train_scores, valid_scores = validation_curve(estimator=RandomForestRegressor(), \n",
    "                                              X=X_train, y=y_train, \n",
    "                                              param_name=\"n_estimators\",\n",
    "                                              param_range=n_estimators_range,\n",
    "                                              cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfacb41-abc6-4a03-835c-68d9e7896eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the validation curve\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "valid_scores_std = np.std(valid_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RF\")\n",
    "plt.xlabel(r\"number of trees\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.8, 1.0)\n",
    "lw = 2\n",
    "plt.semilogx(n_estimators_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(n_estimators_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(n_estimators_range, valid_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(n_estimators_range, valid_scores_mean - valid_scores_std,\n",
    "                 valid_scores_mean + valid_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81653a-a012-4dc2-b25d-b4ad6a9520db",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb3e5a4-cd2d-4cc2-bf2e-f60f29233660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge training and validation data, as required by GridSearchCV\n",
    "# X_train_val = pd.concat([X_train, X_val])\n",
    "# y_train_val = pd.concat([y_train, y_val])                       \n",
    "\n",
    "# # the index list of training and validation data in the merged dataset\n",
    "# # in X_train_val, the first n rows are from X_train and the remaining rows are from X_val. Here n=X_train.shape[0]\n",
    "# ind_train = list(range(X_train.shape[0]))\n",
    "# ind_val = list(range(X_train.shape[0], X_train_val.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f3c89f-3286-4cf8-8e4d-21032bed4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from sklearn import model_selection\n",
    "\n",
    "# # values of n_estimators\n",
    "# parameters = {'n_estimators':[10,30,50,70,100]}\n",
    "\n",
    "# random_state_rf = 10\n",
    "# rf = RandomForestRegressor(random_state=random_state_rf)\n",
    "\n",
    "# # CV: An iterable yielding (train, test) splits as arrays of indices.\n",
    "# clf = model_selection.GridSearchCV(rf, parameters, cv=[(ind_train, ind_val)])\n",
    "\n",
    "# clf.fit(X_train_val, y_train_val)\n",
    "\n",
    "# # we can query the best parameter value and its accuracy score\n",
    "# print (\"The best parameter value is: \")\n",
    "# print (clf.best_params_)\n",
    "# print (\"The best score is: \")\n",
    "# print (clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21774fe-4197-45e8-a18f-87ec1d302e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf_final_model = RandomForestRegressor(n_estimators=clf.best_params_['n_estimators'], random_state=random_state_rf)\n",
    "# rf_final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf842198-05a1-4f00-a436-80732479a7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('The score on the training data:')\n",
    "# print(rf_final_model.score(X_train, y_train))\n",
    "# print('The score on the development data:')\n",
    "# print(rf_final_model.score(X_val, y_val))\n",
    "# print('The score on the test data:')\n",
    "# print(rf_final_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d569a87-170d-41ad-9131-d6631c28b5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
